{
  
    
        "post0": {
            "title": "Orbit in Jupyter",
            "content": "About . A quick post about discovering Orbit and realizing you could use it inside of a notebook. This might be a neat mechanism in which to cover statistics and probability. To take a further look, read the authors book utilizing it, Quantum Country . from IPython.core.display import display, HTML display(HTML(&#39;&#39;&#39;&lt;html&gt; &lt;head&gt; &lt;script type=&quot;module&quot; src=&quot;https://js.withorbit.com/orbit-web-component.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;orbit-reviewarea color=&quot;purple&quot;&gt; &lt;orbit-prompt question=&quot;What&#39;s the working name for Andy&#39;s experimental mnemonic medium platform?&quot; answer=&quot;Orbit&quot; &gt;&lt;/orbit-prompt&gt; &lt;orbit-prompt question=&quot;What&#39;s the new-ish web technology used to embed Orbit prompts into web pages?&quot; answer=&quot;Web components&quot; &gt;&lt;/orbit-prompt&gt; &lt;orbit-prompt question=&quot;Given a right triangle with legs of length $a$ and $b$, what is the length of hypotenuse $c$?&quot; answer=&quot;$$c = sqrt{a^2 + b^2}$$&quot; &gt;&lt;/orbit-prompt&gt; &lt;orbit-prompt question=&quot;What is needed to display HTML in a Jupyter notebook?&quot; answer=&quot;The IPython.core.display package and the display and HTML functions&quot; &gt;&lt;/orbit-prompt&gt; &lt;/orbit-reviewarea&gt; &lt;/body&gt; &lt;/html&gt;&#39;&#39;&#39;)) . . .",
            "url": "https://fp.justin.vc/jupyter/orbit/spaced-repetition/learning/2021/10/07/orbit-spaced-repetition.html",
            "relUrl": "/jupyter/orbit/spaced-repetition/learning/2021/10/07/orbit-spaced-repetition.html",
            "date": " • Oct 7, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Numerai Analysis & Tips in Julia!",
            "content": "using DataFrames # Requires &gt; 0.22.0 for rownums function using CSV using Statistics using LinearAlgebra using Plots using StatsBase using Distributions using MLJ using MLJLinearModels using MLJXGBoostInterface using XGBoost import MLJBase: train_test_pairs # Using for Logistic + CV options, also as an example of how to use Sklearn within Julia using ScikitLearn @sk_import linear_model: (LogisticRegression, LinearRegression) @sk_import model_selection: (TimeSeriesSplit, KFold, GroupKFold, cross_val_score) @sk_import metrics: make_scorer . ┌ Warning: Module model_selection has been ported to Julia - try `import ScikitLearn: CrossValidation` instead └ @ ScikitLearn.Skcore C: Users Justin .julia packages ScikitLearn ssekP src Skcore.jl:179 . PyObject &lt;function make_scorer at 0x000000008F06BA60&gt; . df = CSV.File(&quot;numerai_training_data.csv&quot;) |&gt; DataFrame first(df,5) . 5 rows × 314 columns (omitted printing of 309 columns) . ideradata_typefeature_intelligence1feature_intelligence2 . StringStringStringFloat64Float64 . 1n000315175b67977 | era1 | train | 0.0 | 0.5 | . 2n0014af834a96cdd | era1 | train | 0.0 | 0.0 | . 3n001c93979ac41d4 | era1 | train | 0.25 | 0.5 | . 4n0034e4143f22a13 | era1 | train | 1.0 | 0.0 | . 5n00679d1a636062f | era1 | train | 0.25 | 0.25 | . size(df) . (501808, 314) . features = select(df, r&quot;feature&quot;) |&gt; names df.erano = parse.(Int64, replace.(df.era, &quot;era&quot; =&gt; &quot;&quot;)) eras = df.erano target = &quot;target&quot; length(features) . 310 . feature_groups = Dict(g =&gt; [c for c in features if startswith(c, &quot;feature_$g&quot;)] for g in [&quot;intelligence&quot;, &quot;wisdom&quot;, &quot;charisma&quot;, &quot;dexterity&quot;, &quot;strength&quot;, &quot;constitution&quot;]) . Dict{String, Vector{String}} with 6 entries: &#34;charisma&#34; =&gt; [&#34;feature_charisma1&#34;, &#34;feature_charisma2&#34;, &#34;feature_charism… &#34;constitution&#34; =&gt; [&#34;feature_constitution1&#34;, &#34;feature_constitution2&#34;, &#34;feature… &#34;dexterity&#34; =&gt; [&#34;feature_dexterity1&#34;, &#34;feature_dexterity2&#34;, &#34;feature_dexte… &#34;wisdom&#34; =&gt; [&#34;feature_wisdom1&#34;, &#34;feature_wisdom2&#34;, &#34;feature_wisdom3&#34;, &#34;… &#34;strength&#34; =&gt; [&#34;feature_strength1&#34;, &#34;feature_strength2&#34;, &#34;feature_strengt… &#34;intelligence&#34; =&gt; [&#34;feature_intelligence1&#34;, &#34;feature_intelligence2&#34;, &#34;feature… . # There&#39;s probably (definitely) a better way to write this - [ordinalrank would solve the ranking] function numerai_score(y_true, y_pred, df) rank_pred = sort(combine(groupby(DataFrame(y_pred = y_pred , eras = df.erano , rnum = rownumber.(eachrow(df))) , :eras) , sdf -&gt; sort(sdf, :y_pred) , :eras =&gt; eachindex =&gt; :rank , nrow =&gt; :n) , :rnum) rank_pred = rank_pred.rank ./ rank_pred.n cor(y_true, rank_pred) end # It can also be convenient while working to evaluate based on the regular (pearson) correlation # R2 Score to replicate the Python library outputs function r2_score(y_true, y_pred) @assert length(y_true) == length(y_pred) ss_res = sum((y_true .- y_pred).^2) mean = sum(y_true) / length(y_true) ss_total = sum((y_true .- mean).^2) return 1 - ss_res/(ss_total + eps(eltype(y_pred))) end # cor() returns a matrix with no need for manipulation, so no need to replicate that here . r2_score (generic function with 1 method) . describe(df, :all, cols=:erano) . 1 rows × 13 columns (omitted printing of 3 columns) . variablemeanstdminq25medianq75maxnuniquenmissing . SymbolFloat64Float64Int64Float64Float64Float64Int64NothingInt64 . 1erano | 64.002 | 33.3329 | 1 | 37.0 | 64.0 | 93.0 | 120 | | 0 | . group_df = combine(groupby(df, :erano), nrow =&gt; :count) plot(group_df.erano, group_df.count) . WARNING: CPU random generator seem to be failing, disabling hardware random number generation WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff . combine(groupby(df, :target), nrow =&gt; :count) . 5 rows × 2 columns . targetcount . Float64Int64 . 10.5 | 251677 | . 20.25 | 100053 | . 30.75 | 100045 | . 40.0 | 25016 | . 51.0 | 25017 | . Some of the features are very correlated . Especially within feature groups . feature_corrs = DataFrame(cor(Matrix(df[!, names(df, features)])), features) insertcols!(feature_corrs, 1, :features =&gt; features) first(feature_corrs,5) . 5 rows × 311 columns (omitted printing of 307 columns) . featuresfeature_intelligence1feature_intelligence2feature_intelligence3 . StringFloat64Float64Float64 . 1feature_intelligence1 | 1.0 | -0.0141565 | -0.0244041 | . 2feature_intelligence2 | -0.0141565 | 1.0 | 0.905315 | . 3feature_intelligence3 | -0.0244041 | 0.905315 | 1.0 | . 4feature_intelligence4 | 0.652596 | -0.0280969 | -0.0410859 | . 5feature_intelligence5 | 0.0698683 | 0.184372 | 0.17387 | . first(stack(feature_corrs), 5) . 5 rows × 3 columns . featuresvariablevalue . StringStringFloat64 . 1feature_intelligence1 | feature_intelligence1 | 1.0 | . 2feature_intelligence2 | feature_intelligence1 | -0.0141565 | . 3feature_intelligence3 | feature_intelligence1 | -0.0244041 | . 4feature_intelligence4 | feature_intelligence1 | 0.652596 | . 5feature_intelligence5 | feature_intelligence1 | 0.0698683 | . tdf = stack(feature_corrs) tdf = tdf[coalesce.(tdf.variable .&lt; tdf.features, false), :] sort!(tdf, :value) vcat(first(tdf, 5), last(tdf, 5)) . 10 rows × 3 columns . featuresvariablevalue . StringStringFloat64 . 1feature_constitution9 | feature_constitution112 | -0.855008 | . 2feature_constitution46 | feature_constitution33 | -0.83031 | . 3feature_constitution60 | feature_constitution112 | -0.820694 | . 4feature_constitution87 | feature_constitution46 | -0.815888 | . 5feature_constitution33 | feature_constitution112 | -0.759084 | . 6feature_constitution7 | feature_constitution27 | 0.94892 | . 7feature_constitution79 | feature_constitution13 | 0.949139 | . 8feature_wisdom39 | feature_wisdom31 | 0.954984 | . 9feature_wisdom7 | feature_wisdom46 | 0.963706 | . 10feature_wisdom2 | feature_wisdom12 | 0.968062 | . The correlation can change over time . You can see this by comparing feature correlations on the first half and second half on the training set . df₁ = df[coalesce.(eras .&lt;= median(eras), false), :] df₂ = df[coalesce.(eras .&gt; median(eras), false), :] corr₁ = DataFrame(cor(Matrix(df₁[!, names(df₁, features)])), features) insertcols!(corr₁, 1, :features =&gt; features) corr₁ = stack(corr₁) corr₁ = corr₁[coalesce.(corr₁.variable .&lt; corr₁.features, false), :] corr₂ = DataFrame(cor(Matrix(df₂[!, names(df₂, features)])), features) insertcols!(corr₂, 1, :features =&gt; features) corr₂ = stack(corr₂) corr₂ = corr₂[coalesce.(corr₂.variable .&lt; corr₂.features, false), :] tdf = leftjoin(corr₁, corr₂, on = [:variable, :features], makeunique=true) rename!(tdf, [:value, :value_1] .=&gt; [:corr₁, :corr₂]) tdf.corr_diff = tdf.corr₂ - tdf.corr₁ sort!(tdf, :corr_diff) vcat(first(tdf,5), last(tdf,5)) . 10 rows × 5 columns . featuresvariablecorr₁corr₂corr_diff . StringStringFloat64Float64?Float64 . 1feature_intelligence9 | feature_intelligence11 | 0.0913519 | -0.128851 | -0.220203 | . 2feature_intelligence10 | feature_dexterity12 | 0.548931 | 0.343117 | -0.205814 | . 3feature_intelligence11 | feature_dexterity9 | 0.0787148 | -0.12707 | -0.205785 | . 4feature_dexterity12 | feature_dexterity1 | 0.653528 | 0.447942 | -0.205587 | . 5feature_intelligence11 | feature_intelligence10 | 0.0750222 | -0.130511 | -0.205534 | . 6feature_wisdom22 | feature_intelligence8 | -0.0883461 | 0.117772 | 0.206119 | . 7feature_wisdom43 | feature_intelligence4 | -0.102438 | 0.103758 | 0.206197 | . 8feature_wisdom33 | feature_intelligence4 | -0.0789296 | 0.133664 | 0.212593 | . 9feature_wisdom43 | feature_intelligence8 | -0.121306 | 0.115194 | 0.236501 | . 10feature_wisdom33 | feature_intelligence8 | -0.0917593 | 0.150549 | 0.242308 | . Some features are predictive on their own . feature_scores = Dict(feature =&gt; numerai_score(df.target, df[!, feature], df) for feature in features); . sort(collect(feature_scores), by=x-&gt;x[2]) . 310-element Vector{Pair{String, Float64}}: &#34;feature_dexterity7&#34; =&gt; -0.011504914975281387 &#34;feature_dexterity6&#34; =&gt; -0.011161569760516648 &#34;feature_dexterity4&#34; =&gt; -0.011051275935746707 &#34;feature_charisma69&#34; =&gt; -0.010221311263804505 &#34;feature_dexterity11&#34; =&gt; -0.010198611285978189 &#34;feature_charisma9&#34; =&gt; -0.01005025481510148 &#34;feature_dexterity12&#34; =&gt; -0.008647990681418269 &#34;feature_dexterity14&#34; =&gt; -0.008611934226827449 &#34;feature_dexterity3&#34; =&gt; -0.007607475423078082 &#34;feature_constitution91&#34; =&gt; -0.007343474478571397 &#34;feature_dexterity8&#34; =&gt; -0.0072798010318430835 &#34;feature_constitution56&#34; =&gt; -0.007206474137472462 &#34;feature_constitution110&#34; =&gt; -0.007154545491821277 ⋮ &#34;feature_strength4&#34; =&gt; 0.010184232051437234 &#34;feature_charisma81&#34; =&gt; 0.010224703123621929 &#34;feature_charisma46&#34; =&gt; 0.01039946229179084 &#34;feature_charisma66&#34; =&gt; 0.010507207995266913 &#34;feature_charisma54&#34; =&gt; 0.010507614931830764 &#34;feature_charisma6&#34; =&gt; 0.010580151207446348 &#34;feature_charisma76&#34; =&gt; 0.010608014161745269 &#34;feature_charisma18&#34; =&gt; 0.010697616377184683 &#34;feature_charisma19&#34; =&gt; 0.01071636820945142 &#34;feature_charisma37&#34; =&gt; 0.01089177370157534 &#34;feature_strength14&#34; =&gt; 0.01160884774563975 &#34;feature_strength34&#34; =&gt; 0.012487781133717898 . by_era_correlation = sort(Dict(values(erano)[1] =&gt; cor(tdf.target, tdf.feature_strength34) for (erano, tdf) in pairs(groupby(df, :erano)))) plot(by_era_correlation) . function rolling_mean(arr, n) rs = cumsum(arr)[n:end] .- cumsum([0.0; arr])[1:end-n] return rs ./ n end n_window = 10 plot(Dict(zip(collect(n_window-1:length(by_era_correlation)), rolling_mean(collect(values(by_era_correlation)),n_window)))) . Gotcha: MSE looks worse than correlation out of sample . Models will generally be overconfident, so even if they are good at ranking rows, the Mean-Squared-Error of the residuals could be larger than event the Mean-Squared-Error of the target (r-squared&lt;0) . df₁ = df[coalesce.(eras .&lt;= median(eras), false), :] df₂ = df[coalesce.(eras .&gt; median(eras), false), :]; . Linear = @load LinearRegressor pkg=MLJLinearModels verbosity=0 linear = Linear() lin₁ = machine(linear, df₁[!, names(df₁, features)], df₁.target) fit!(lin₁, verbosity=0) lin₂ = machine(linear, df₂[!, names(df₂, features)], df₂.target) fit!(lin₂, verbosity=0); . r2₁ = [ r2_score(dfₓ.target, MLJ.predict(model, dfₓ[!, names(dfₓ, features)])) for dfₓ in [df1, df2] for model in [lin1, lin2]] DataFrame(reshape(r2₁, 2, 2), [&quot;eval_on_1&quot;,&quot;eval_on_2&quot;]) . 2 rows × 2 columns . eval_on_1eval_on_2 . Float64Float64 . 10.00409275 | -0.000543157 | . 20.000574622 | 0.00315522 | . corrs = [ numerai_score(MLJ.predict(model, dfₓ[!, names(dfₓ, features)]), dfₓ.target, dfₓ) for dfₓ in [df₁, df₂] for model in [lin₁, lin₂]] DataFrame(reshape(corrs, 2, 2), [&quot;eval_on_1&quot;,&quot;eval_on_2&quot;]) . 2 rows × 2 columns . eval_on_1eval_on_2 . Float64Float64 . 10.058282 | 0.0287217 | . 20.0319412 | 0.0528229 | . . XGB = @load XGBoostRegressor pkg=XGBoost verbosity=0 xgb = XGB() xgb₁ = machine(xgb, df₁[!, names(df₁, features)], df₁.target) fit!(xgb₁, verbosity=0) xgb₂ = machine(xgb, df₂[!, names(df₂, features)], df₂.target) fit!(xgb₂, verbosity=0); . r2₂ = [ r2_score(dfₓ.target, MLJ.predict(model, dfₓ[!, names(dfₓ, features)])) for dfₓ in [df₁, df₂] for model in [xgb₁, xgb₂]] DataFrame(reshape(r2₂, 2, 2), [&quot;eval_on_1&quot;,&quot;eval_on_2&quot;]) . 2 rows × 2 columns . eval_on_1eval_on_2 . Float64Float64 . 10.123117 | -0.0237936 | . 2-0.0199959 | 0.12788 | . corrs2 = [ numerai_score(MLJ.predict(model, dfₓ[!, names(dfₓ, features)]), dfₓ.target, dfₓ) for dfₓ in [df₁, df₂] for model in [xgb₁, xgb₂]] DataFrame(reshape(corrs2, 2, 2), [&quot;eval_on_1&quot;,&quot;eval_on_2&quot;]) . 2 rows × 2 columns . eval_on_1eval_on_2 . Float64Float64 . 10.383874 | 0.0240443 | . 20.0229365 | 0.392287 | . Gotcha: {0, 1} are noticeably different from {0.25, 0.75} . This makes training a classifier one-versus-rest behave counterintuitively. . Specifically, the 0-vs-rest and 1-vs-rest classifiers seem to learn how to pick out extreme targets, and their predictions are the most correlated . logistic = LogisticRegression() ScikitLearn.fit!(logistic, Matrix(df[!, names(df, features)]), convert.(Int, df.target*4)) ScikitLearn.score(logistic, Matrix(df[!, names(df, features)]), convert.(Int, df.target*4)) . C: Users Justin .julia conda 3 lib site-packages sklearn linear_model _logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1): STOP: TOTAL NO. of ITERATIONS REACHED LIMIT. Increase the number of iterations (max_iter) or scale the data as shown in: https://scikit-learn.org/stable/modules/preprocessing.html Please also refer to the documentation for alternative solver options: https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression n_iter_i = _check_optimize_result( . 0.5012315467270351 . log_corrs = cor(transpose(ScikitLearn.predict_proba(logistic, Matrix(df[!, names(df, features)]))), dims=2) display(log_corrs) heatmap(log_corrs, c=palette(:RdYlGn)) . 5×5 Matrix{Float64}: 1.0 0.468155 -0.903881 0.42197 0.947252 0.468155 1.0 -0.704718 0.517207 0.428423 -0.903881 -0.704718 1.0 -0.71843 -0.914418 0.42197 0.517207 -0.71843 1.0 0.498854 0.947252 0.428423 -0.914418 0.498854 1.0 . prob_matrix = ScikitLearn.predict_proba(logistic, Matrix(df[!, names(df, features)])) classes = logistic.classes_ numerai_score(df.target, prob_matrix * classes, df) . 0.050658929537343786 . linear = LinearRegression() ScikitLearn.fit!(linear, Matrix(df[!, names(df, features)]), df.target) ScikitLearn.score(linear, Matrix(df[!, names(df, features)]), df.target) preds = ScikitLearn.predict(linear, Matrix(df[!, names(df, features)])) numerai_score(df.target, preds, df) . 0.05107803901831943 . Gotcha: eras are homogenous, but different from each other . Random cross-validation will look much better than cross-validating by era . Even for a simple linear model, taking a random shuffle reports a correlation of 4.3%, but a time series split reports a lower score of 3.4% . #ScikitLearn.fit!(linear, Matrix(df[!, names(df, features)]), df.target) . PyObject LinearRegression() . crossvalidators = [KFold(5), KFold(5, shuffle = true), GroupKFold(5), TimeSeriesSplit(5)] for cv in crossvalidators println(cv) println( mean( cross_val_score(estimator = LinearRegression(), X = Matrix(df[!, names(df, features)]), y = df.target, cv = cv, groups = eras, scoring = make_scorer(cor, greater_is_better = true) ) ) ) end . PyObject KFold(n_splits=5, random_state=None, shuffle=False) 0.03332624500455265 PyObject KFold(n_splits=5, random_state=None, shuffle=True) 0.03955268244942284 PyObject GroupKFold(n_splits=5) 0.03475937229926111 PyObject TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None) 0.030947709608331396 . Eras can be more or less applicable to other eras . You can test this be splitting the eras into blocks of 10, training on each block, and evaluating on each other block. . eras10 = (eras .÷ 10) * 10 countmap(eras10) . Dict{Int64, Int64} with 13 entries: 20 =&gt; 37444 110 =&gt; 45070 60 =&gt; 46831 30 =&gt; 41101 0 =&gt; 24515 80 =&gt; 43971 90 =&gt; 45609 40 =&gt; 43439 70 =&gt; 40403 50 =&gt; 48186 10 =&gt; 34600 120 =&gt; 4532 100 =&gt; 46107 . gdf = copy(df) gdf[:, :eras10 ] = eras10 gdf = groupby(filter(row -&gt; row[:eras10] &lt; 120, xdf), :eras10); results10 = DataFrame(train_era = Int32[], test_era = Int32[], value = Float32[]) for train_era in keys(gdf) println(train_era[1]) gdf₁ = gdf[train_era] model = LinearRegression() ScikitLearn.fit!(model, Matrix(gdf₁[!, names(gdf₁, features)]), gdf₁.target) for test_era in keys(gdf) gdf₂ = gdf[test_era] push!(results10, [train_era[1], test_era[1], cor(gdf₂.target, ScikitLearn.predict(model, Matrix(gdf₂[!, names(gdf₂, features)])))]) end end . 0 10 20 30 40 50 60 70 80 90 100 110 . results_df = unstack(results10, :test_era, :value) . 12 rows × 13 columns (omitted printing of 6 columns) . train_era01020304050 . Int32Float32?Float32?Float32?Float32?Float32?Float32? . 10 | 0.14615 | 0.0321283 | 0.0354025 | 0.0287675 | 0.0221984 | 0.00701235 | . 210 | 0.0421759 | 0.114813 | 0.0287059 | 0.0298504 | 0.0336937 | 0.00471899 | . 320 | 0.0431496 | 0.0334976 | 0.113055 | 0.0366226 | 0.0167489 | 0.00565709 | . 430 | 0.0357169 | 0.0339307 | 0.0396031 | 0.109884 | 0.0402888 | 0.0208269 | . 540 | 0.035735 | 0.0417183 | 0.0204626 | 0.0403498 | 0.100257 | 0.0144214 | . 650 | 0.015032 | 0.00959667 | 0.00685722 | 0.0242685 | 0.0151326 | 0.104185 | . 760 | 0.00690366 | 0.0159851 | 0.00419466 | 0.0195585 | 0.012405 | 0.00967648 | . 870 | 0.034285 | 0.0252239 | 0.0220385 | 0.0285308 | 0.0232155 | 0.00198308 | . 980 | 0.0395826 | 0.0268682 | 0.0115186 | 0.0217091 | 0.0177472 | 0.00252007 | . 1090 | 0.0328201 | 0.029052 | 0.0229233 | 0.031348 | 0.0199844 | 0.0100413 | . 11100 | 0.0283381 | 0.0179835 | 0.0217198 | 0.00991935 | 0.00779132 | 0.0120947 | . 12110 | 0.00181083 | 0.0183579 | 0.00941574 | 0.0067019 | 0.0147348 | 0.0164994 | . heatmap(clamp!(Matrix(select(results_df, Not(:train_era))), -.04, .04), c=palette(:RdYlGn)) . Here is an advanced paper that talks about generalization. Eras can be thought about in the same way that &quot;distributions&quot; or &quot;environments&quot; are talked about here https://arxiv.org/pdf/1907.02893.pdf . Gotcha: Since the signal-to-noise ratio is so low, models can take many more iterations than expected, and have scarily high in-sample performance . df₁ = df[coalesce.(eras .&lt;= median(eras), false), :] df₂ = df[coalesce.(eras .&gt; median(eras), false), :]; . function our_score(preds, dtrain) return &quot;score&quot;, cor(get_info(dtrain, &quot;label&quot;), preds) end dtrain = DMatrix(Matrix(df₁[!, features]), label=df₁.target) dtest = DMatrix(Matrix(df₂[!, features]), label=df₂.target) dall = DMatrix(Matrix(df[!, features]), label=df.target); . # the source code shows only that it prints to stderr - one could redirect it to an IOBuffer and regex parse it into an # array but realistically the amount of effort isn&#39;t worth it, since one can clearly see the out-of-sample performance # differneces purely from the numbers printed param = Dict( &quot;eta&quot; =&gt; 0.1, &quot;max_depth&quot; =&gt; 3, &quot;objective&quot; =&gt; &quot;reg:squarederror&quot;, &quot;eval_metric&quot; =&gt; &quot;rmse&quot; ) xgboost(dtrain, 100, param = param, watchlist = [(dtrain, &quot;train&quot;), (dtest, &quot;test&quot;)], feval = our_score ) . Booster(Ptr{Nothing} @0x00000000c46a4790) . The results are sensitive to the choice of parameters, which should be picked through cross-validation . df₁ = df[coalesce.(eras .&lt;= median(eras), false), :] df₂ = df[coalesce.(eras .&gt; median(eras), false), :]; . XGB = @load XGBoostRegressor pkg=XGBoost verbosity=0 Linear = @load LinearRegressor pkg=MLJLinearModels verbosity=0 Elastic = @load ElasticNetRegressor pkg=MLJLinearModels verbosity=0 . ElasticNetRegressor . models = vcat( [Linear()], [Elastic(lambda = λ) for λ in [0.01, 0.005, 0.002, 0.001, 0.0005, 0.0002, 0.0001, 0.00005, 0.00002, 0.00001]], [XGB()], [XGB(eta = 0.01, num_round=1000)], [XGB(eta = 0.01, colsample_bytree=0.1, num_round=1000)], [XGB(eta = 0.01, colsample_bytree=0.1, num_round=1000, max_depth=5)], [XGB(eta = 0.001, colsample_bytree=0.1, num_round=1000, max_depth=5)] ); . 0.056996 seconds (110.33 k allocations: 7.421 MiB, 102.88% compilation time) . for model in models print(&quot; -- &quot;, model, &quot; n&quot;) mach = machine(model, df₁[!, features], df₁.target) MLJ.fit!(mach, verbosity=0) outsample = numerai_score(df₂.target, MLJ.predict(mach, df₂[!, features]), df₂) insample = numerai_score(df₁.target, MLJ.predict(mach, df₁[!, features]), df₁) print(&quot;outsample: $outsample, insample: $insample&quot;, &quot; n&quot;) end . -- LinearRegressor @226 outsample: 0.028025599207339144, insample: 0.06275168899240204 -- ElasticNetRegressor @411 outsample: 0.027651106932304964, insample: 0.061801048380003165 -- ElasticNetRegressor @697 outsample: 0.027651115862462477, insample: 0.061800987594603896 -- ElasticNetRegressor @825 outsample: 0.02765108322778513, insample: 0.06180104261606859 -- ElasticNetRegressor @024 outsample: 0.027651162275441423, insample: 0.061801053881855784 -- ElasticNetRegressor @510 outsample: 0.027651155706182137, insample: 0.06180105710588575 -- ElasticNetRegressor @526 outsample: 0.027651162860262833, insample: 0.06180104657865728 -- ElasticNetRegressor @754 outsample: 0.0276511455748371, insample: 0.061801044145696406 -- ElasticNetRegressor @689 outsample: 0.02765113464601516, insample: 0.061801044145696406 -- ElasticNetRegressor @244 outsample: 0.027651141667503418, insample: 0.06180103987617271 -- ElasticNetRegressor @526 outsample: 0.027651141667503418, insample: 0.06180103987617271 -- XGBoostRegressor @609 outsample: 0.024815763345799297, insample: 0.4033048140864821 -- XGBoostRegressor @496 outsample: 0.03659074980295988, insample: 0.34474251174858644 -- XGBoostRegressor @986 outsample: 0.03897987810857149, insample: 0.3118486054318112 -- XGBoostRegressor @039 outsample: 0.039683297779925394, insample: 0.20312468355680283 -- XGBoostRegressor @194 outsample: 0.034509192497652864, insample: 0.11544644084833998 1176.550459 seconds (57.51 M allocations: 143.696 GiB, 1.12% gc time, 0.19% compilation time) . Gotcha: Models with large exposures to individual features tend to perform poorly or inconsistently out of sample . XGB = @load XGBoostRegressor pkg=XGBoost verbosity=0 xgb = XGB(eta = 0.01, max_depth=5, num_round=1000); mach = machine(xgb, df₁[!, features], df₁.target) MLJ.fit!(mach, verbosity=0) xgb_preds = MLJ.predict(mach, df₂[!, features]); . xgb_preds . 248653-element Vector{Float32}: 0.5092171 0.51353323 0.5298325 0.50988734 0.50764424 0.50148475 0.504006 0.49748185 0.49696985 0.48918203 0.50696886 0.51324135 0.48414978 ⋮ 0.48918062 0.47421244 0.5090075 0.48367783 0.47870287 0.5039986 0.4987926 0.49181792 0.51567954 0.5039868 0.48160774 0.48305735 . Our predictions have correlation &gt; 0.2 in either direction for some single features! . Sure hope those features continue to act as they have in the past! . cor_list = [] for feature in features append!(cor_list, cor(df₂[!, feature], xgb_preds)) end describe(DataFrame(cor_list = cor_list), :all) . 1 rows × 13 columns (omitted printing of 5 columns) . variablemeanstdminq25medianq75max . SymbolFloat64Float64Float64Float64Float64Float64Float64 . 1cor_list | 0.0484105 | 0.0816448 | -0.229774 | 0.00417808 | 0.0457962 | 0.108646 | 0.232515 | . function norm_neut(df, columns, feats, proportion=1.0) scores = quantile(Normal(0.0,1.0),(ordinalrank(df[!, columns]) .- 0.5) ./ length(df[!, columns])) exposures = Matrix(df[!, feats]) neutralized = scores - proportion * exposures * (pinv(exposures) * scores) return neutralized / std(neutralized) end; . df₂.preds = xgb_preds df₂[:, :preds_neutralized] = combine(x -&gt; norm_neut(x, :preds, features, 0.5), groupby(df₂, :erano)).x1 x_min = minimum(df₂.preds_neutralized) x_max = maximum(df₂.preds_neutralized) X_std = (df₂.preds_neutralized .- x_min) / (x_max .- x_min) df₂[!, :preds_neutralized] = X_scaled = X_std * (1 - 0) .+ 0; . describe(df₂.preds_neutralized) . Summary Stats: Length: 248653 Missing Count: 0 Mean: 0.512301 Minimum: 0.000000 1st Quartile: 0.445243 Median: 0.510633 3rd Quartile: 0.577324 Maximum: 1.000000 Type: Float32 . Now our single feature exposures are much smaller . cor_list2 = [] for feature in features append!(cor_list2, cor(df₂[!, feature], df₂.preds_neutralized)) end describe(DataFrame(cor_list2 = cor_list2), :all) . 1 rows × 13 columns (omitted printing of 5 columns) . variablemeanstdminq25medianq75max . SymbolFloat64Float64Float64Float64Float64Float64Float64 . 1cor_list2 | 0.0361128 | 0.05318 | -0.146887 | 0.00775736 | 0.0337416 | 0.0753399 | 0.155376 | . Our overall score goes down, but the scores are more consistent than before. This leads to a higher sharpe . unbalanced_scores_per_era = combine(x -&gt; cor(x.preds, x.target), groupby(df₂, :era)) balanced_scores_per_era = combine(x -&gt; cor(x.preds_neutralized, x.target), groupby(df₂, :era)); . println(&quot;score for high feature exposure: &quot;, mean(unbalanced_scores_per_era.x1)) println(&quot;score for balanced feature expo: &quot;, mean(balanced_scores_per_era.x1)) println(&quot;std for high feature exposure: &quot;, std(unbalanced_scores_per_era.x1)) println(&quot;std for balanced feature expo: &quot;, std(balanced_scores_per_era.x1)) println(&quot;sharpe for high feature exposure: &quot;, mean(unbalanced_scores_per_era.x1)/std(unbalanced_scores_per_era.x1)) println(&quot;sharpe for balanced feature expo: &quot;, mean(balanced_scores_per_era.x1)/std(balanced_scores_per_era.x1)) . score for high feature exposure: 0.0368068530006 score for balanced feature expo: 0.03288299544568849 std for high feature exposure: 0.03848940885417861 std for balanced feature expo: 0.03158550581657646 sharpe for high feature exposure: 0.9562852248535912 sharpe for balanced feature expo: 1.0410786402043652 . describe(balanced_scores_per_era.x1) . Summary Stats: Length: 56 Missing Count: 0 Mean: 0.032883 Minimum: -0.065154 1st Quartile: 0.013038 Median: 0.030797 3rd Quartile: 0.061884 Maximum: 0.091098 Type: Float64 . describe(unbalanced_scores_per_era.x1) . Summary Stats: Length: 56 Missing Count: 0 Mean: 0.036807 Minimum: -0.085174 1st Quartile: 0.014656 Median: 0.033550 3rd Quartile: 0.062175 Maximum: 0.112687 Type: Float64 .",
            "url": "https://fp.justin.vc/numerai/mlj/scikit-learn/datascience/julia/2021/07/14/analysis_and_tips_julia.html",
            "relUrl": "/numerai/mlj/scikit-learn/datascience/julia/2021/07/14/analysis_and_tips_julia.html",
            "date": " • Jul 14, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Custom Metrics in PyCaret for Numerai",
            "content": "About . I put together this notebook on how to use custom metrics with PyCaret, specifically for the Numerai compeittion. . import numpy as np import pandas as pd import csv from pathlib import Path from sklearn.metrics import make_scorer from scipy.stats import spearmanr, pearsonr from pycaret.regression import * TARGET_NAME = f&quot;target&quot; PREDICTION_NAME = f&quot;prediction&quot; . . training_data = read_csv(&quot;numerai_training_data.csv&quot;) tournament_data = read_csv(&quot;numerai_tournament_data.csv&quot;) # Sampling for ease of demo/repeatability - obviously would use full set for competition training_data = training_data.sample(500) tournament_data = tournament_data.sample(500) feature_names = [f for f in training_data.columns if f.startswith(&quot;feature&quot;) or f == TARGET_NAME] . training_data.head(5) . era data_type feature_intelligence1 feature_intelligence2 feature_intelligence3 feature_intelligence4 feature_intelligence5 feature_intelligence6 feature_intelligence7 feature_intelligence8 feature_intelligence9 feature_intelligence10 feature_intelligence11 feature_intelligence12 feature_charisma1 feature_charisma2 feature_charisma3 feature_charisma4 feature_charisma5 feature_charisma6 feature_charisma7 feature_charisma8 feature_charisma9 feature_charisma10 feature_charisma11 feature_charisma12 feature_charisma13 feature_charisma14 feature_charisma15 feature_charisma16 feature_charisma17 feature_charisma18 feature_charisma19 feature_charisma20 feature_charisma21 feature_charisma22 feature_charisma23 feature_charisma24 feature_charisma25 feature_charisma26 feature_charisma27 feature_charisma28 feature_charisma29 feature_charisma30 feature_charisma31 feature_charisma32 feature_charisma33 feature_charisma34 feature_charisma35 feature_charisma36 feature_charisma37 feature_charisma38 feature_charisma39 feature_charisma40 feature_charisma41 feature_charisma42 feature_charisma43 feature_charisma44 feature_charisma45 feature_charisma46 feature_charisma47 feature_charisma48 feature_charisma49 feature_charisma50 feature_charisma51 feature_charisma52 feature_charisma53 feature_charisma54 feature_charisma55 feature_charisma56 feature_charisma57 feature_charisma58 feature_charisma59 feature_charisma60 feature_charisma61 feature_charisma62 feature_charisma63 feature_charisma64 feature_charisma65 feature_charisma66 feature_charisma67 feature_charisma68 feature_charisma69 feature_charisma70 feature_charisma71 feature_charisma72 feature_charisma73 feature_charisma74 feature_charisma75 feature_charisma76 feature_charisma77 feature_charisma78 feature_charisma79 feature_charisma80 feature_charisma81 feature_charisma82 feature_charisma83 feature_charisma84 feature_charisma85 feature_charisma86 feature_strength1 feature_strength2 feature_strength3 feature_strength4 feature_strength5 feature_strength6 feature_strength7 feature_strength8 feature_strength9 feature_strength10 feature_strength11 feature_strength12 feature_strength13 feature_strength14 feature_strength15 feature_strength16 feature_strength17 feature_strength18 feature_strength19 feature_strength20 feature_strength21 feature_strength22 feature_strength23 feature_strength24 feature_strength25 feature_strength26 feature_strength27 feature_strength28 feature_strength29 feature_strength30 feature_strength31 feature_strength32 feature_strength33 feature_strength34 feature_strength35 feature_strength36 feature_strength37 feature_strength38 feature_dexterity1 feature_dexterity2 feature_dexterity3 feature_dexterity4 feature_dexterity5 feature_dexterity6 feature_dexterity7 feature_dexterity8 feature_dexterity9 feature_dexterity10 feature_dexterity11 feature_dexterity12 feature_dexterity13 feature_dexterity14 feature_constitution1 feature_constitution2 feature_constitution3 feature_constitution4 feature_constitution5 feature_constitution6 feature_constitution7 feature_constitution8 feature_constitution9 feature_constitution10 feature_constitution11 feature_constitution12 feature_constitution13 feature_constitution14 feature_constitution15 feature_constitution16 feature_constitution17 feature_constitution18 feature_constitution19 feature_constitution20 feature_constitution21 feature_constitution22 feature_constitution23 feature_constitution24 feature_constitution25 feature_constitution26 feature_constitution27 feature_constitution28 feature_constitution29 feature_constitution30 feature_constitution31 feature_constitution32 feature_constitution33 feature_constitution34 feature_constitution35 feature_constitution36 feature_constitution37 feature_constitution38 feature_constitution39 feature_constitution40 feature_constitution41 feature_constitution42 feature_constitution43 feature_constitution44 feature_constitution45 feature_constitution46 feature_constitution47 feature_constitution48 feature_constitution49 feature_constitution50 feature_constitution51 feature_constitution52 feature_constitution53 feature_constitution54 feature_constitution55 feature_constitution56 feature_constitution57 feature_constitution58 feature_constitution59 feature_constitution60 feature_constitution61 feature_constitution62 feature_constitution63 feature_constitution64 feature_constitution65 feature_constitution66 feature_constitution67 feature_constitution68 feature_constitution69 feature_constitution70 feature_constitution71 feature_constitution72 feature_constitution73 feature_constitution74 feature_constitution75 feature_constitution76 feature_constitution77 feature_constitution78 feature_constitution79 feature_constitution80 feature_constitution81 feature_constitution82 feature_constitution83 feature_constitution84 feature_constitution85 feature_constitution86 feature_constitution87 feature_constitution88 feature_constitution89 feature_constitution90 feature_constitution91 feature_constitution92 feature_constitution93 feature_constitution94 feature_constitution95 feature_constitution96 feature_constitution97 feature_constitution98 feature_constitution99 feature_constitution100 feature_constitution101 feature_constitution102 feature_constitution103 feature_constitution104 feature_constitution105 feature_constitution106 feature_constitution107 feature_constitution108 feature_constitution109 feature_constitution110 feature_constitution111 feature_constitution112 feature_constitution113 feature_constitution114 feature_wisdom1 feature_wisdom2 feature_wisdom3 feature_wisdom4 feature_wisdom5 feature_wisdom6 feature_wisdom7 feature_wisdom8 feature_wisdom9 feature_wisdom10 feature_wisdom11 feature_wisdom12 feature_wisdom13 feature_wisdom14 feature_wisdom15 feature_wisdom16 feature_wisdom17 feature_wisdom18 feature_wisdom19 feature_wisdom20 feature_wisdom21 feature_wisdom22 feature_wisdom23 feature_wisdom24 feature_wisdom25 feature_wisdom26 feature_wisdom27 feature_wisdom28 feature_wisdom29 feature_wisdom30 feature_wisdom31 feature_wisdom32 feature_wisdom33 feature_wisdom34 feature_wisdom35 feature_wisdom36 feature_wisdom37 feature_wisdom38 feature_wisdom39 feature_wisdom40 feature_wisdom41 feature_wisdom42 feature_wisdom43 feature_wisdom44 feature_wisdom45 feature_wisdom46 target . id . n6346c8f8784a565 era75 | train | 0.75 | 1.00 | 1.00 | 0.50 | 0.50 | 0.50 | 0.25 | 1.00 | 0.75 | 0.75 | 0.75 | 0.50 | 1.00 | 0.25 | 0.50 | 0.00 | 0.00 | 0.75 | 0.25 | 1.00 | 0.25 | 0.25 | 1.00 | 0.50 | 0.75 | 0.00 | 1.00 | 0.25 | 0.00 | 1.00 | 1.00 | 0.00 | 0.75 | 0.00 | 0.75 | 0.25 | 1.00 | 0.00 | 0.00 | 0.75 | 0.00 | 0.00 | 0.5 | 1.00 | 0.00 | 0.25 | 0.00 | 0.75 | 1.00 | 0.00 | 0.50 | 0.00 | 0.00 | 0.75 | 1.00 | 0.00 | 0.50 | 0.50 | 1.0 | 1.00 | 0.25 | 0.50 | 0.50 | 1.00 | 0.75 | 0.75 | 0.75 | 0.0 | 0.00 | 1.00 | 0.00 | 0.00 | 0.0 | 0.75 | 0.75 | 0.00 | 0.00 | 0.00 | 0.0 | 0.50 | 0.25 | 0.75 | 0.0 | 0.25 | 0.25 | 0.00 | 0.75 | 1.00 | 0.00 | 0.25 | 0.00 | 0.75 | 1.00 | 0.25 | 0.00 | 1.00 | 0.5 | 0.75 | 0.00 | 0.00 | 1.0 | 0.00 | 0.75 | 0.5 | 0.00 | 0.75 | 0.00 | 1.00 | 0.00 | 0.75 | 0.25 | 1.00 | 1.00 | 0.00 | 0.50 | 1.0 | 1.0 | 0.75 | 0.00 | 0.00 | 0.00 | 1.00 | 0.00 | 0.00 | 1.00 | 0.75 | 1.00 | 0.75 | 0.00 | 0.00 | 0.00 | 1.00 | 0.00 | 1.00 | 1.0 | 0.75 | 0.25 | 0.75 | 1.0 | 1.00 | 0.75 | 1.00 | 1.00 | 1.00 | 0.5 | 1.0 | 0.75 | 1.00 | 1.0 | 1.00 | 0.25 | 0.25 | 1.00 | 0.00 | 0.5 | 0.5 | 1.00 | 0.00 | 1.00 | 0.5 | 0.0 | 0.75 | 1.0 | 0.75 | 0.0 | 0.00 | 0.00 | 0.00 | 0.00 | 0.75 | 0.50 | 0.0 | 1.0 | 0.50 | 0.25 | 0.75 | 1.0 | 0.00 | 1.00 | 0.50 | 0.75 | 0.25 | 1.00 | 0.0 | 0.00 | 0.00 | 0.00 | 0.25 | 0.0 | 0.00 | 0.00 | 0.75 | 0.75 | 1.0 | 0.00 | 0.25 | 0.00 | 0.00 | 0.00 | 1.00 | 0.50 | 1.00 | 0.75 | 0.0 | 1.0 | 0.00 | 0.25 | 0.00 | 0.50 | 0.5 | 0.75 | 0.50 | 0.0 | 0.00 | 0.00 | 1.0 | 0.50 | 0.0 | 1.00 | 0.75 | 0.75 | 0.25 | 0.25 | 0.50 | 0.00 | 0.25 | 0.0 | 0.00 | 1.0 | 0.50 | 0.75 | 0.50 | 0.00 | 0.75 | 0.75 | 0.75 | 0.5 | 0.00 | 0.00 | 0.0 | 0.00 | 0.25 | 1.0 | 1.00 | 0.00 | 1.00 | 0.00 | 0.25 | 0.00 | 0.00 | 0.00 | 0.00 | 0.25 | 0.5 | 0.00 | 0.0 | 0.00 | 0.25 | 0.0 | 0.0 | 0.25 | 0.25 | 0.00 | 0.5 | 0.00 | 0.00 | 0.00 | 0.25 | 0.25 | 0.0 | 0.25 | 0.00 | 0.00 | 0.0 | 0.25 | 0.00 | 0.00 | 0.00 | 0.00 | 0.25 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.25 | 0.00 | 0.00 | 0.25 | 0.00 | 0.00 | 0.25 | 0.00 | 0.25 | 0.00 | 0.25 | 0.00 | 0.25 | 0.00 | 0.50 | 0.00 | 0.00 | 0.00 | 0.50 | 0.50 | 0.75 | 0.00 | 0.25 | 0.00 | 0.25 | 0.25 | . n46dccf4bc8006a8 era75 | train | 0.00 | 1.00 | 1.00 | 0.00 | 0.25 | 0.50 | 0.25 | 0.00 | 1.00 | 1.00 | 0.00 | 0.25 | 0.25 | 0.75 | 0.25 | 1.00 | 0.50 | 1.00 | 1.00 | 0.75 | 0.00 | 0.25 | 0.50 | 1.00 | 0.75 | 1.00 | 0.25 | 1.00 | 1.00 | 1.00 | 0.50 | 0.25 | 0.75 | 0.25 | 0.75 | 0.75 | 0.25 | 1.00 | 0.75 | 0.75 | 0.75 | 0.75 | 1.0 | 1.00 | 1.00 | 1.00 | 1.00 | 1.00 | 0.75 | 1.00 | 0.75 | 0.75 | 0.75 | 1.00 | 1.00 | 1.00 | 0.25 | 0.50 | 0.0 | 0.75 | 0.50 | 1.00 | 1.00 | 0.75 | 0.75 | 1.00 | 1.00 | 0.5 | 0.50 | 0.75 | 0.50 | 0.25 | 0.5 | 1.00 | 1.00 | 0.75 | 0.50 | 0.75 | 1.0 | 0.75 | 0.25 | 1.00 | 1.0 | 1.00 | 0.25 | 1.00 | 1.00 | 1.00 | 0.75 | 0.50 | 0.75 | 1.00 | 1.00 | 0.75 | 0.50 | 0.75 | 1.0 | 0.75 | 0.50 | 0.50 | 0.0 | 0.75 | 0.50 | 0.5 | 0.50 | 0.25 | 0.50 | 0.50 | 0.50 | 0.25 | 0.75 | 0.75 | 0.75 | 1.00 | 0.75 | 0.5 | 0.0 | 0.50 | 0.75 | 0.50 | 0.50 | 0.00 | 0.00 | 0.50 | 0.75 | 0.75 | 0.00 | 0.50 | 0.25 | 0.25 | 0.50 | 0.75 | 0.75 | 0.75 | 0.5 | 0.50 | 1.00 | 1.00 | 1.0 | 0.75 | 1.00 | 1.00 | 1.00 | 1.00 | 1.0 | 1.0 | 1.00 | 0.00 | 1.0 | 0.25 | 0.25 | 1.00 | 0.25 | 0.75 | 0.0 | 0.0 | 0.00 | 0.25 | 0.75 | 0.0 | 1.0 | 0.00 | 0.0 | 0.75 | 0.5 | 0.50 | 0.25 | 0.25 | 1.00 | 0.75 | 0.25 | 0.5 | 0.0 | 0.75 | 0.50 | 0.75 | 0.0 | 0.75 | 0.25 | 0.75 | 1.00 | 0.50 | 1.00 | 0.5 | 0.75 | 0.75 | 0.50 | 0.25 | 0.5 | 0.50 | 0.00 | 0.25 | 0.50 | 0.0 | 1.00 | 0.00 | 1.00 | 0.25 | 1.00 | 0.50 | 1.00 | 1.00 | 0.50 | 1.0 | 0.0 | 0.25 | 0.25 | 1.00 | 1.00 | 1.0 | 1.00 | 0.50 | 0.5 | 0.75 | 0.00 | 0.0 | 0.75 | 1.0 | 1.00 | 0.50 | 0.75 | 0.00 | 1.00 | 0.25 | 0.25 | 0.75 | 0.5 | 0.50 | 0.0 | 0.50 | 0.75 | 0.50 | 0.50 | 0.75 | 0.75 | 0.75 | 1.0 | 0.25 | 0.50 | 0.0 | 0.00 | 0.50 | 0.0 | 0.75 | 1.00 | 1.00 | 0.25 | 0.75 | 0.75 | 0.75 | 0.25 | 0.25 | 0.25 | 1.0 | 0.50 | 0.5 | 0.25 | 0.00 | 0.5 | 0.0 | 0.50 | 0.00 | 0.75 | 0.5 | 0.00 | 0.50 | 0.50 | 0.25 | 0.25 | 0.0 | 0.50 | 0.25 | 0.50 | 0.5 | 0.25 | 0.50 | 0.75 | 0.50 | 0.25 | 0.25 | 0.25 | 0.75 | 0.25 | 0.25 | 0.25 | 0.50 | 0.75 | 0.00 | 0.50 | 0.00 | 0.25 | 0.25 | 0.25 | 0.25 | 0.25 | 0.50 | 0.00 | 0.75 | 0.75 | 0.00 | 0.25 | 0.00 | 0.25 | 0.75 | 0.75 | 0.00 | 0.25 | 0.25 | 0.50 | 0.50 | 0.25 | . n3e1605f37041c0c era6 | train | 0.75 | 0.25 | 0.00 | 0.75 | 0.75 | 0.50 | 0.25 | 0.75 | 0.00 | 0.00 | 0.75 | 1.00 | 0.00 | 0.50 | 0.75 | 0.00 | 0.75 | 1.00 | 0.50 | 0.50 | 1.00 | 1.00 | 0.25 | 0.75 | 0.00 | 0.75 | 0.50 | 0.25 | 0.00 | 0.00 | 0.00 | 0.75 | 0.00 | 0.25 | 1.00 | 0.75 | 0.75 | 0.25 | 0.25 | 0.00 | 1.00 | 0.25 | 0.0 | 0.00 | 0.75 | 0.50 | 0.50 | 0.00 | 0.00 | 0.25 | 1.00 | 1.00 | 1.00 | 1.00 | 0.00 | 0.25 | 0.75 | 0.25 | 1.0 | 0.00 | 0.75 | 0.00 | 0.00 | 0.00 | 0.00 | 1.00 | 0.50 | 0.5 | 1.00 | 0.25 | 1.00 | 0.25 | 1.0 | 0.25 | 0.00 | 0.75 | 0.75 | 0.00 | 0.0 | 0.00 | 1.00 | 0.00 | 1.0 | 0.50 | 0.75 | 0.25 | 1.00 | 0.00 | 0.00 | 1.00 | 0.75 | 0.50 | 0.00 | 0.00 | 0.75 | 1.00 | 0.0 | 1.00 | 1.00 | 0.00 | 1.0 | 1.00 | 0.50 | 0.5 | 0.50 | 0.50 | 0.50 | 0.75 | 1.00 | 0.25 | 0.50 | 1.00 | 0.75 | 0.25 | 0.50 | 1.0 | 1.0 | 0.50 | 1.00 | 0.75 | 0.00 | 1.00 | 0.00 | 0.50 | 0.50 | 0.75 | 0.75 | 0.50 | 0.00 | 0.00 | 0.50 | 0.75 | 0.50 | 0.75 | 1.0 | 0.50 | 0.00 | 0.00 | 0.0 | 0.25 | 0.00 | 0.00 | 0.25 | 0.00 | 0.0 | 0.0 | 0.00 | 0.50 | 0.0 | 0.50 | 0.75 | 0.00 | 0.00 | 0.00 | 1.0 | 1.0 | 0.50 | 0.25 | 0.00 | 1.0 | 0.0 | 1.00 | 0.0 | 0.00 | 0.0 | 0.50 | 0.25 | 0.75 | 0.00 | 0.25 | 0.25 | 0.5 | 0.0 | 0.00 | 0.25 | 0.75 | 0.5 | 0.00 | 1.00 | 0.00 | 0.25 | 0.50 | 0.00 | 0.0 | 0.00 | 0.25 | 0.00 | 0.50 | 0.5 | 0.50 | 0.50 | 0.00 | 0.25 | 0.5 | 0.00 | 1.00 | 0.25 | 0.75 | 0.25 | 1.00 | 0.00 | 1.00 | 0.50 | 0.0 | 0.5 | 1.00 | 0.75 | 1.00 | 0.00 | 0.0 | 0.00 | 0.25 | 0.0 | 0.25 | 0.00 | 0.5 | 0.25 | 1.0 | 0.75 | 0.75 | 0.75 | 0.00 | 0.00 | 1.00 | 0.75 | 0.50 | 0.5 | 0.00 | 0.5 | 1.00 | 0.00 | 0.00 | 0.50 | 0.75 | 0.75 | 1.00 | 0.0 | 0.00 | 0.50 | 0.0 | 1.00 | 0.25 | 0.5 | 1.00 | 0.00 | 0.00 | 0.25 | 0.00 | 0.25 | 0.50 | 1.00 | 1.00 | 0.00 | 0.0 | 0.00 | 0.5 | 0.50 | 0.50 | 0.0 | 1.0 | 0.25 | 1.00 | 0.25 | 0.5 | 0.00 | 0.25 | 1.00 | 0.00 | 0.00 | 1.0 | 0.00 | 0.00 | 1.00 | 0.0 | 1.00 | 0.25 | 0.00 | 0.00 | 0.00 | 0.00 | 0.25 | 0.00 | 0.00 | 0.00 | 0.50 | 1.00 | 0.00 | 1.00 | 0.00 | 0.75 | 0.00 | 0.50 | 0.00 | 0.25 | 0.00 | 0.00 | 0.75 | 0.00 | 0.00 | 0.25 | 0.25 | 0.25 | 0.00 | 0.00 | 0.00 | 0.25 | 0.75 | 0.00 | 0.00 | 0.00 | 0.25 | . na662ad0039c3091 era107 | train | 0.50 | 0.75 | 0.75 | 0.25 | 0.50 | 0.75 | 0.75 | 0.00 | 0.75 | 0.75 | 0.25 | 0.50 | 0.25 | 0.25 | 1.00 | 0.75 | 0.25 | 1.00 | 1.00 | 0.75 | 0.50 | 1.00 | 0.75 | 0.50 | 0.50 | 0.50 | 0.75 | 0.50 | 0.75 | 0.25 | 0.75 | 0.25 | 1.00 | 0.50 | 0.50 | 0.25 | 0.25 | 0.25 | 0.50 | 0.25 | 0.50 | 0.25 | 0.5 | 0.25 | 0.50 | 1.00 | 0.50 | 1.00 | 0.25 | 0.25 | 0.50 | 0.50 | 0.25 | 0.50 | 1.00 | 0.50 | 1.00 | 1.00 | 0.0 | 0.00 | 1.00 | 0.25 | 0.25 | 0.50 | 0.25 | 0.75 | 1.00 | 1.0 | 0.25 | 0.75 | 0.25 | 0.75 | 0.5 | 0.75 | 1.00 | 0.25 | 1.00 | 1.00 | 0.5 | 0.50 | 0.75 | 1.00 | 0.5 | 1.00 | 0.75 | 0.50 | 0.50 | 0.25 | 0.25 | 1.00 | 0.25 | 0.25 | 0.25 | 0.75 | 0.00 | 0.25 | 1.0 | 0.25 | 0.75 | 0.50 | 0.5 | 0.75 | 1.00 | 0.5 | 0.25 | 0.50 | 0.25 | 0.75 | 0.25 | 0.50 | 1.00 | 1.00 | 0.50 | 0.25 | 0.50 | 1.0 | 0.5 | 0.50 | 0.25 | 0.25 | 0.25 | 0.75 | 0.25 | 0.75 | 0.50 | 0.25 | 0.75 | 0.50 | 0.00 | 0.25 | 0.75 | 1.00 | 0.25 | 0.50 | 1.0 | 0.50 | 0.75 | 0.75 | 0.5 | 0.00 | 0.50 | 0.25 | 0.00 | 0.50 | 0.5 | 0.5 | 0.50 | 0.00 | 0.5 | 0.25 | 0.50 | 0.75 | 0.00 | 0.00 | 0.0 | 0.0 | 0.75 | 0.25 | 0.75 | 0.0 | 0.5 | 0.50 | 0.5 | 0.25 | 0.5 | 0.25 | 0.00 | 0.00 | 0.50 | 1.00 | 0.00 | 0.0 | 0.0 | 0.75 | 0.00 | 1.00 | 1.0 | 0.00 | 0.50 | 0.25 | 0.50 | 0.25 | 0.75 | 0.0 | 0.25 | 0.25 | 0.75 | 0.75 | 0.0 | 0.25 | 0.25 | 0.25 | 1.00 | 1.0 | 0.75 | 0.00 | 0.50 | 0.00 | 0.25 | 0.25 | 0.25 | 0.75 | 0.75 | 1.0 | 1.0 | 0.25 | 0.25 | 1.00 | 0.25 | 1.0 | 1.00 | 1.00 | 0.5 | 0.25 | 0.25 | 1.0 | 0.25 | 1.0 | 1.00 | 0.00 | 1.00 | 0.00 | 0.50 | 0.00 | 0.25 | 0.25 | 0.0 | 0.25 | 0.5 | 0.75 | 0.25 | 0.75 | 0.25 | 1.00 | 1.00 | 1.00 | 1.0 | 0.00 | 0.00 | 0.0 | 0.25 | 1.00 | 1.0 | 1.00 | 1.00 | 0.75 | 0.00 | 0.25 | 1.00 | 0.25 | 0.50 | 0.25 | 0.25 | 0.5 | 0.25 | 0.5 | 0.00 | 0.25 | 0.0 | 0.5 | 0.25 | 0.00 | 0.00 | 1.0 | 0.75 | 0.75 | 0.75 | 1.00 | 1.00 | 0.5 | 1.00 | 0.00 | 1.00 | 0.0 | 0.25 | 0.75 | 1.00 | 0.75 | 0.25 | 0.75 | 1.00 | 0.75 | 0.00 | 1.00 | 0.50 | 1.00 | 0.50 | 0.75 | 0.50 | 0.25 | 0.50 | 0.00 | 0.75 | 1.00 | 0.50 | 0.25 | 1.00 | 1.00 | 1.00 | 0.75 | 0.75 | 0.75 | 0.50 | 0.75 | 1.00 | 0.25 | 1.00 | 0.50 | 0.75 | 1.00 | 0.50 | . nf324eff3bcbf017 era99 | train | 0.25 | 0.25 | 0.50 | 0.75 | 0.00 | 0.25 | 0.50 | 0.75 | 0.50 | 0.50 | 0.75 | 0.25 | 0.50 | 0.50 | 0.00 | 0.00 | 0.75 | 1.00 | 0.25 | 0.00 | 1.00 | 0.75 | 0.00 | 0.25 | 0.25 | 0.00 | 0.00 | 0.50 | 0.00 | 0.00 | 0.50 | 0.75 | 0.00 | 0.00 | 0.00 | 0.50 | 0.50 | 0.75 | 0.50 | 0.00 | 1.00 | 0.25 | 0.0 | 0.00 | 0.00 | 1.00 | 0.75 | 0.00 | 0.00 | 0.50 | 0.00 | 1.00 | 0.25 | 1.00 | 0.25 | 1.00 | 0.25 | 0.00 | 0.5 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 1.00 | 1.00 | 0.0 | 0.75 | 0.25 | 0.25 | 0.00 | 1.0 | 0.25 | 0.00 | 0.75 | 0.00 | 0.25 | 0.5 | 0.00 | 1.00 | 0.25 | 1.0 | 0.50 | 0.00 | 1.00 | 1.00 | 0.00 | 0.50 | 1.00 | 0.75 | 0.25 | 0.00 | 0.00 | 0.75 | 1.00 | 0.0 | 1.00 | 1.00 | 0.25 | 1.0 | 1.00 | 0.00 | 0.5 | 0.50 | 0.75 | 0.25 | 1.00 | 0.50 | 1.00 | 0.00 | 0.00 | 1.00 | 0.50 | 0.50 | 1.0 | 1.0 | 0.50 | 0.50 | 0.00 | 0.25 | 1.00 | 0.00 | 0.50 | 0.50 | 0.75 | 1.00 | 1.00 | 0.00 | 0.25 | 0.50 | 0.00 | 0.50 | 1.00 | 1.0 | 0.50 | 0.50 | 0.50 | 0.0 | 0.00 | 0.25 | 0.00 | 0.00 | 0.25 | 0.5 | 0.5 | 0.00 | 0.25 | 0.0 | 0.00 | 0.75 | 0.00 | 0.50 | 0.00 | 0.0 | 0.5 | 1.00 | 0.00 | 0.00 | 0.5 | 0.0 | 1.00 | 0.5 | 0.00 | 1.0 | 0.00 | 0.00 | 1.00 | 0.25 | 0.75 | 0.00 | 0.5 | 0.5 | 0.00 | 0.50 | 0.75 | 1.0 | 0.00 | 1.00 | 0.00 | 0.25 | 1.00 | 0.00 | 0.0 | 0.25 | 0.25 | 1.00 | 1.00 | 1.0 | 0.00 | 0.50 | 0.00 | 0.75 | 0.5 | 0.25 | 1.00 | 0.25 | 0.50 | 0.25 | 1.00 | 0.00 | 0.75 | 1.00 | 0.0 | 0.5 | 1.00 | 1.00 | 0.25 | 0.00 | 0.0 | 0.00 | 0.75 | 0.0 | 0.50 | 0.00 | 0.5 | 0.50 | 0.0 | 1.00 | 0.00 | 1.00 | 0.50 | 0.00 | 0.00 | 1.00 | 0.25 | 0.5 | 0.00 | 0.5 | 0.75 | 0.00 | 0.00 | 0.25 | 0.75 | 0.75 | 0.50 | 0.0 | 0.50 | 0.25 | 0.5 | 1.00 | 1.00 | 0.5 | 0.50 | 0.25 | 0.00 | 0.50 | 0.50 | 1.00 | 0.25 | 0.75 | 1.00 | 0.50 | 0.0 | 0.00 | 1.0 | 0.50 | 0.50 | 0.0 | 1.0 | 0.50 | 1.00 | 0.50 | 1.0 | 0.00 | 0.00 | 0.50 | 0.75 | 0.00 | 0.0 | 0.00 | 0.50 | 0.75 | 0.5 | 0.25 | 0.00 | 0.25 | 0.00 | 0.00 | 1.00 | 0.25 | 0.00 | 0.50 | 0.00 | 0.25 | 0.75 | 0.00 | 0.50 | 0.00 | 1.00 | 0.00 | 0.00 | 0.25 | 1.00 | 0.00 | 0.00 | 0.50 | 0.00 | 0.00 | 0.50 | 0.25 | 0.00 | 0.00 | 0.00 | 0.00 | 0.25 | 0.50 | 0.00 | 1.00 | 0.00 | 0.25 | . reg = setup( data=training_data[feature_names], target=TARGET_NAME, session_id=42, silent = True ) . Description Value . 0 session_id | 42 | . 1 Target | target | . 2 Original Data | (500, 311) | . 3 Missing Values | False | . 4 Numeric Features | 310 | . 5 Categorical Features | 0 | . 6 Ordinal Features | False | . 7 High Cardinality Features | False | . 8 High Cardinality Method | None | . 9 Transformed Train Set | (349, 310) | . 10 Transformed Test Set | (151, 310) | . 11 Shuffle Train-Test | True | . 12 Stratify Train-Test | False | . 13 Fold Generator | KFold | . 14 Fold Number | 10 | . 15 CPU Jobs | -1 | . 16 Use GPU | False | . 17 Log Experiment | False | . 18 Experiment Name | reg-default-name | . 19 USI | 4790 | . 20 Imputation Type | simple | . 21 Iterative Imputation Iteration | None | . 22 Numeric Imputer | mean | . 23 Iterative Imputation Numeric Model | None | . 24 Categorical Imputer | constant | . 25 Iterative Imputation Categorical Model | None | . 26 Unknown Categoricals Handling | least_frequent | . 27 Normalize | False | . 28 Normalize Method | None | . 29 Transformation | False | . 30 Transformation Method | None | . 31 PCA | False | . 32 PCA Method | None | . 33 PCA Components | None | . 34 Ignore Low Variance | False | . 35 Combine Rare Levels | False | . 36 Rare Level Threshold | None | . 37 Numeric Binning | False | . 38 Remove Outliers | False | . 39 Outliers Threshold | None | . 40 Remove Multicollinearity | False | . 41 Multicollinearity Threshold | None | . 42 Clustering | False | . 43 Clustering Iteration | None | . 44 Polynomial Features | False | . 45 Polynomial Degree | None | . 46 Trignometry Features | False | . 47 Polynomial Threshold | None | . 48 Group Features | False | . 49 Feature Selection | False | . 50 Feature Selection Method | classic | . 51 Features Selection Threshold | None | . 52 Feature Interaction | False | . 53 Feature Ratio | False | . 54 Interaction Threshold | None | . 55 Transform Target | False | . 56 Transform Target Method | box-cox | . . Adding Metrics . PyCaret makes use of scikit-learn&#39;s make_scorer. After initialization of the PyCaret regressor/classifier module, you simply utilize add_metric to attach them to PyCaret&#39;s list of metrics. . # Submissions are scored by spearman correlation def spearman(y_true, y_pred): ret_score = spearmanr(y_true, y_pred)[0] return ret_score if not np.isnan(ret_score) else 0.0 def pearson(y_true, y_pred): ret_score = pearsonr(y_true, y_pred)[0] return ret_score if not np.isnan(ret_score) else 0.0 spearman_corr = make_scorer(spearman, needs_proba=False) pearson_corr = make_scorer(pearson, needs_proba=False) add_metric(&#39;pearson&#39;, &#39;CORR&#39;, pearson) add_metric(&#39;spear&#39;, &#39;SPEAR&#39;, spearman) . Name SPEAR Display Name SPEAR Score Function &lt;function spearman at 0x0000019EFE4F0310&gt; Scorer make_scorer(spearman) Target pred Args {} Greater is Better True Custom True Name: spear, dtype: object . get_metrics() . Name Display Name Score Function Scorer Target Args Greater is Better Custom . ID . mae MAE | MAE | &lt;function mean_absolute_error at 0x0000019EF9A... | neg_mean_absolute_error | pred | {} | False | False | . mse MSE | MSE | &lt;function mean_squared_error at 0x0000019EF9A0... | neg_mean_squared_error | pred | {} | False | False | . rmse RMSE | RMSE | &lt;function mean_squared_error at 0x0000019EF9A0... | neg_root_mean_squared_error | pred | {&#39;squared&#39;: False} | False | False | . r2 R2 | R2 | &lt;function r2_score at 0x0000019EF9A05A60&gt; | r2 | pred | {} | True | False | . rmsle RMSLE | RMSLE | &lt;function RMSLEMetricContainer.__init__.&lt;local... | make_scorer(root_mean_squared_log_error, great... | pred | {} | False | False | . mape MAPE | MAPE | &lt;function MAPEMetricContainer.__init__.&lt;locals... | make_scorer(mean_absolute_percentage_error, gr... | pred | {} | False | False | . pearson CORR | CORR | &lt;function pearson at 0x0000019EFE4F0550&gt; | make_scorer(pearson) | pred | {} | True | True | . spear SPEAR | SPEAR | &lt;function spearman at 0x0000019EFE4F0310&gt; | make_scorer(spearman) | pred | {} | True | True | . Running the Models with New Metrics . Adding these metrics allow them to be shown in all new model creation by PyCaret. Simply optimize when using tune_model and it will optimize by your new metric. . xgb = create_model(&#39;xgboost&#39;, fold = 5) . MAE MSE RMSE R2 RMSLE MAPE CORR SPEAR . 0 0.1677 | 0.0580 | 0.2409 | -0.3001 | 0.1686 | 0.3182 | 0.0235 | 0.1182 | . 1 0.2180 | 0.0798 | 0.2825 | -0.7472 | 0.1818 | 0.3694 | -0.1615 | -0.1551 | . 2 0.2124 | 0.0680 | 0.2607 | -0.1435 | 0.1697 | 0.4688 | 0.0718 | 0.0193 | . 3 0.1803 | 0.0590 | 0.2429 | -0.1409 | 0.1754 | 0.3664 | 0.2891 | 0.2976 | . 4 0.1930 | 0.0593 | 0.2435 | -0.0715 | 0.1689 | 0.3733 | 0.1697 | 0.1444 | . Mean 0.1943 | 0.0648 | 0.2541 | -0.2807 | 0.1729 | 0.3792 | 0.0785 | 0.0849 | . SD 0.0190 | 0.0083 | 0.0159 | 0.2450 | 0.0051 | 0.0491 | 0.1506 | 0.1495 | . tuned_xgb = tune_model(xgb, optimize=&#39;spear&#39;, fold= 5, n_iter = 10, search_library=&quot;optuna&quot;) . MAE MSE RMSE R2 RMSLE MAPE CORR SPEAR . 0 0.1286 | 0.0446 | 0.2113 | -0.0000 | 0.1475 | 0.2349 | -0.0111 | 0.0088 | . 1 0.1714 | 0.0571 | 0.2390 | -0.2511 | 0.1498 | 0.2730 | 0.0715 | 0.0511 | . 2 0.1714 | 0.0607 | 0.2464 | -0.0215 | 0.1575 | 0.3648 | 0.0867 | 0.0992 | . 3 0.1500 | 0.0536 | 0.2315 | -0.0356 | 0.1668 | 0.3047 | 0.0144 | 0.0618 | . 4 0.1667 | 0.0562 | 0.2370 | -0.0152 | 0.1618 | 0.2975 | 0.1831 | 0.1981 | . Mean 0.1576 | 0.0544 | 0.2330 | -0.0647 | 0.1567 | 0.2950 | 0.0689 | 0.0838 | . SD 0.0165 | 0.0054 | 0.0119 | 0.0939 | 0.0072 | 0.0426 | 0.0674 | 0.0640 | . tournament_data[PREDICTION_NAME] = tuned_xgb.predict(tournament_data[feature_names[:-1]]) . tournament_data[PREDICTION_NAME].to_csv(&quot;submission.csv&quot;, header=True) . . Note: For a more in-depth treatment of Numerai in general, please refer to their sample notebook .",
            "url": "https://fp.justin.vc/numerai/pycaret/scikit-learn/datascience/2021/06/13/pycaret-numerai-custom-metric.html",
            "relUrl": "/numerai/pycaret/scikit-learn/datascience/2021/06/13/pycaret-numerai-custom-metric.html",
            "date": " • Jun 13, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "Justin.vc",
          "content": "",
          "url": "https://fp.justin.vc/_pages/about.html",
          "relUrl": "/_pages/about.html",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
      ,"page8": {
          "title": "",
          "content": "{“/_pages/about.html”:”https://justin.vc”} .",
          "url": "https://fp.justin.vc/redirects.json",
          "relUrl": "/redirects.json",
          "date": ""
      }
      
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://fp.justin.vc/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

  
  

}